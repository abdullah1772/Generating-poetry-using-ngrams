{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "436d5758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b9d03d",
   "metadata": {},
   "source": [
    "# Urdu to roman phonetic dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dd8e07",
   "metadata": {},
   "source": [
    "##### mapping urdu phonetic roman against urdu words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35310af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "urdu_dictionary = { \n",
    "    \"آ\" : \"aa\",\n",
    "    \"ا\" : \"a\",\n",
    "    \"ب\" : \"b\",\n",
    "    \"پ\" : \"p\",\n",
    "    \"ت\" : \"t\",\n",
    "    \"ٹ\" : \"t\",\n",
    "    \"ث\" : \"sa\",\n",
    "    \"ج\" : \"j\",\n",
    "    \"چ\" : \"ch\",\n",
    "    \"ح\" : \"ha\",\n",
    "    \"خ\" : \"kh\",\n",
    "    \"د\" : \"d\",\n",
    "    \"ڈ\" : \"da\",\n",
    "    \"ذ\" : \"za\",\n",
    "    \"ر\" : \"r\",\n",
    "    \"ڑ\" : \"ra\",\n",
    "    \"ز\" : \"za\",\n",
    "    \"ژ\" : \"ze\",\n",
    "    \"س\" : \"s\",\n",
    "    \"ش\" : \"sh\",\n",
    "    \"ص\" : \"sa\",\n",
    "    \"ض\" : \"zu\",\n",
    "    \"ط\" : \"ta\",\n",
    "    \"ظ\" : \"za\",\n",
    "    \"ع\" : \"a\",\n",
    "    \"غ\" : \"gh\",\n",
    "    \"ف\" : \"f\",\n",
    "    \"ق\" : \"k\",\n",
    "    \"ک\" : \"k\",\n",
    "    \"گ\" : \"gh\",\n",
    "    \"ل\" : \"l\",\n",
    "    \"م\" : \"m\",\n",
    "    \"ن\" : \"n\",\n",
    "    \"ں\" : \"n\",\n",
    "    \"و\" : \"w\",\n",
    "    \"ہ\" : \"ha\",\n",
    "    \"ی\" : \"y\",\n",
    "    \"ے\" : \"ay\",\n",
    "    \"ء\" : \"a\",\n",
    "    \"ئ\" : \"i\",\n",
    "    \"ھ\" : \"h\",\n",
    "    \"أ\"  : \"a\",\n",
    "    \"ؤ\"  : \"ao\",\n",
    "    \"ه\"  : \"ha\",\n",
    "    \"ي\"  : \"y\",\n",
    "    \"ۂ\"  : \"h\",\n",
    "    \"ۓ\"  : \"ya\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdac587",
   "metadata": {},
   "source": [
    "# Converting urdu to roman urdu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04344e59",
   "metadata": {},
   "source": [
    "#######A function that takes a urdu string as an input and maps roman agaist urdu characters based on the dictionary and returns a roman urdu string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6304b951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def urdu_to_roman(Urdu_string):\n",
    "    \n",
    "    Urdu_string_lst=Urdu_string.split()\n",
    "    roman_lst=[]\n",
    "    \n",
    "    for word in Urdu_string_lst:\n",
    "        temp = word\n",
    "        for i, j in urdu_dictionary.items():      \n",
    "            temp = temp.replace(i, j)\n",
    "        roman_lst.append(temp)\n",
    "        \n",
    "    Roman_string=' '.join(roman_lst)\n",
    "    \n",
    "    return Roman_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5246e586",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13886f6",
   "metadata": {},
   "source": [
    "###### Fisrst of all i am reading the poetry file into a string, than i am sending that string to my preprocessing function that removes punctuation, remove double spaces, join some words together and seprate some and returns a normal urdu string which is again stored in a list of sentences. Further all sentences with a length of 3 or less are removed as they are only names or poetry titles. I am also adding sentence start and end tags on each sentence and removing all empty lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b38767ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessing(sentence):\n",
    "    start='<s>'\n",
    "    end='</s>'\n",
    "    punct=['?' , ':' , '؟' , '،' , '*' , '\\'' , '!' ,'`' , '‘' , '’' , '\"' , '%' , '.' , '_' , '“' ,'ـ', '۔',]\n",
    "    temp=''\n",
    "    sentence=sentence.split()\n",
    "    for word in sentence:\n",
    "        if word not in punct:\n",
    "            temp = temp + word + ' '\n",
    "    \n",
    "    sentence=temp.split()\n",
    "    temp=' '\n",
    "    \n",
    "    for word in sentence:\n",
    "        for char in word:\n",
    "            if char not in punct:\n",
    "                temp = temp + char\n",
    "        temp = temp + ' '\n",
    "    temp = start + temp + end\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fbb7aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'poetry.txt'\n",
    "sentences=[]\n",
    "sentence=''\n",
    "temp=''\n",
    "with open(file, 'r', encoding=\"utf-8\") as text:\n",
    "    sentence = text.readlines()\n",
    "for line in sentence:\n",
    "    temp=(Preprocessing(line))\n",
    "    temp=' '.join(temp.split())\n",
    "    sentences.append(temp)\n",
    "    \n",
    "sentences = filter(lambda x: x != '', sentences)\n",
    "sentences=list(sentences)\n",
    "\n",
    "for line in sentences:\n",
    "        temp=line.split()\n",
    "        if(len(temp) <= 3):\n",
    "            sentences.remove(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b16a64",
   "metadata": {},
   "source": [
    "# Generating corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc419b35",
   "metadata": {},
   "source": [
    "##### I am building a simple corpus wich have all the sentences stored as a text, and i am calculating the total length of corpus excluding sentece start and end tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7a79c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=' '.join(sentences)\n",
    "temp= corpus.count(\"</s>\") + corpus.count(\"<s>\")\n",
    "corpus_length_uni=len(corpus) - temp\n",
    "corpus_length=len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248f86ae",
   "metadata": {},
   "source": [
    "# Unigram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32d655b",
   "metadata": {},
   "source": [
    "##### in the unigram i am spliting the whole corpus, turing the corpus into a dictionary which stres all unique words agaist their freqencies. Next i am removing the sentence start ad tags because they don't contribute in word making. Find all the unique words and calculate the total number of vocabulary. Next its simply dividing the count of each word against total count vocabulary and storing it in a probability dictionary agaist each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89f31253",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_words=corpus.split()\n",
    "unigram_freq_dict=Counter(corpus_words)\n",
    "unigram_freq_dict.pop(\"</s>\")\n",
    "unigram_freq_dict.pop(\"<s>\")\n",
    "no_of_unique_words=len(unigram_freq_dict)\n",
    "denominator = corpus_length_uni\n",
    "unigram_prob_dict={}\n",
    "for key in unigram_freq_dict:\n",
    "    numerator=unigram_freq_dict.get(key,0 )\n",
    "    prob=numerator/denominator\n",
    "    unigram_prob_dict[key] = prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5e061f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words=[]\n",
    "for key in unigram_freq_dict:\n",
    "    unique_words.append(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba6310d",
   "metadata": {},
   "source": [
    "# Bigram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eca0c1c",
   "metadata": {},
   "source": [
    "##### for making bigrams i am simply checking 2 consectively occuring words, and making them into a tuple and storing them in a list. I am mainiting a list of tuples. Next i am using conditional freq distribution from nltk library to calculate the occurance of all the unique touples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13beec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram=[]\n",
    "lst=[]\n",
    "start='<s>'\n",
    "end='</s>'\n",
    "for sentence in sentences:\n",
    "    sentence=sentence.split()\n",
    "    temp=None\n",
    "    for word in sentence:\n",
    "        if temp != None:\n",
    "            if temp != start and word != end:\n",
    "                lst=[]\n",
    "                lst.append(temp)\n",
    "                lst.append(word)\n",
    "                lst=tuple(lst)\n",
    "                bigram.append(lst)\n",
    "        temp = word\n",
    "        \n",
    "bigram_freq = nltk.ConditionalFreqDist()\n",
    "for tup in bigram:\n",
    "    bigram_freq[len(tup)][tup] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd611025",
   "metadata": {},
   "source": [
    "# Backwar Bigram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8952197",
   "metadata": {},
   "source": [
    "##### It's the same as bigram except that i am swapping the places of touples with eachother for creating backward bigrams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37efb2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Back_bigram=[]\n",
    "lst=[]\n",
    "start='<s>'\n",
    "end='</s>'\n",
    "for sentence in sentences:\n",
    "    sentence=sentence.split()\n",
    "    temp=None\n",
    "    for word in sentence:\n",
    "        if temp != None:\n",
    "            if temp != start and word != end:\n",
    "                lst=[]\n",
    "                lst.append(word)\n",
    "                lst.append(temp)\n",
    "                lst=tuple(lst)\n",
    "                Back_bigram.append(lst)\n",
    "        temp = word\n",
    "        \n",
    "Back_bigram_freq = nltk.ConditionalFreqDist()\n",
    "for tup in Back_bigram:\n",
    "    Back_bigram_freq[len(tup)][tup] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafb7fef",
   "metadata": {},
   "source": [
    "# Trigram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a4bc78",
   "metadata": {},
   "source": [
    "#### for making trigrams i am simply checking 3 consectively occuring words, and making them into a tuple and storing them in a list. I am mainiting a list of tuples. Next i am using conditional freq distribution from nltk library to calculate the occurance of all the unique touples¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e9bf03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Trigram=[]\n",
    "lst=[]\n",
    "start='<s>'\n",
    "end='</s>'\n",
    "for sentence in sentences:\n",
    "    sentence=sentence.split()\n",
    "    for i in range(0, len(sentence)-2):\n",
    "        if sentence[i] != start and sentence[i+2] != end:\n",
    "                    lst=[]\n",
    "                    lst.append(sentence[i])\n",
    "                    lst.append(sentence[i+1])\n",
    "                    lst.append(sentence[i+2])\n",
    "                    lst=tuple(lst)\n",
    "                    Trigram.append(lst)\n",
    "\n",
    "trigram_freq = nltk.ConditionalFreqDist()\n",
    "for tup in Trigram:\n",
    "    trigram_freq[len(tup)][tup] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6626cf97",
   "metadata": {},
   "source": [
    "# Creating generation models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b75ae46",
   "metadata": {},
   "source": [
    "the bigram generation functions recives a word, along the list of avilable bigrams, and their frequencies, and the total vocab count. I check if the recived word exists in all avaiable bigram, i get the no of occurances of that bigram. I am using la place smoothing. Probabilities for all the existing bigrams are calculated and stored in a dictionary. I am taking the maximum value from that and return the next existing word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "780a144f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_gen(bigram,start_word,bigram_freq,unigram_freq_dict,no_of_unique_words):\n",
    "    temp_dict={}\n",
    "    num=0\n",
    "    den=0\n",
    "    prob=0\n",
    "    for tup in bigram:\n",
    "        if (start_word == tup[0]):\n",
    "            num=bigram_freq[len(tup)][tup]+1\n",
    "            den=unigram_freq_dict.get(tup[0],0)\n",
    "            den = den + no_of_unique_words\n",
    "            prob=num/den\n",
    "            temp_dict[tup]=prob\n",
    "#             print(tup,start_word)\n",
    "#             print(prob)\n",
    "    max_key = max(temp_dict, key=temp_dict.get)\n",
    "#     print(max_key[1])\n",
    "    return max_key[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c196c53",
   "metadata": {},
   "source": [
    "It works the same as bigram and returns the previous existing word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b00ed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Back_bigram_gen(Back_bigram,start_word,Back_bigram_freq,unigram_freq_dict,no_of_unique_words):\n",
    "    temp_dict={}\n",
    "    num=0\n",
    "    den=0\n",
    "    prob=0\n",
    "    for tup in Back_bigram:\n",
    "        if (start_word == tup[0]):\n",
    "            num=Back_bigram_freq[len(tup)][tup]+1\n",
    "            den=unigram_freq_dict.get(tup[0],0)\n",
    "            den = den + no_of_unique_words\n",
    "            prob=num/den\n",
    "            temp_dict[tup]=prob\n",
    "#             print(tup,start_word)\n",
    "#             print(prob)\n",
    "    max_key = max(temp_dict, key=temp_dict.get)\n",
    "#     print(max_key[1])\n",
    "    return max_key[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8da2d3e",
   "metadata": {},
   "source": [
    "In trigram, i am also making use of la place smoothing. A occuring word comes, its probablity of existing is calculated and it returns the 2 occuring words, given that word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67a3409e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigram_gen(Trigram,bigram_freq,start_word,trigram_freq,unigram_freq_dict,no_of_unique_words):\n",
    "    temp_dict={}\n",
    "    num=0\n",
    "    den=0\n",
    "    prob=0\n",
    "    for tup in Trigram:\n",
    "        if (start_word == tup[0]):\n",
    "            num=trigram_freq[len(tup)][tup]+1\n",
    "            den=bigram_freq[2][(tup[0],tup[1])]\n",
    "            den = den + no_of_unique_words\n",
    "            prob=num/den\n",
    "            temp_dict[tup]=prob\n",
    "#             print(tup,start_word)\n",
    "#             print(prob)\n",
    "    max_key = max(temp_dict, key=temp_dict.get)\n",
    "    #print(max_key)\n",
    "    return max_key[1],max_key[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03450e92",
   "metadata": {},
   "source": [
    "I am using all diffrent models to genrate poetry. What i am doing is picking a word a random, sending it to the model i want to use, generate it's next or previous occuring words, append them into a verse and append the verse into a Ghazal list. After the Ghazal is generated in urdu its sent to a urdu to roamn converter and its displayed.\n",
    "To improve the accuracy of the models, i have scrapped some other potry datasets, about an 1.5 mb of petry where as gven was just 150 kb, that has improved my models and have increased number of words and helps with rhyming as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e13b12b",
   "metadata": {},
   "source": [
    "# Generating Poetry using Bi directional bigram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb80e2c8",
   "metadata": {},
   "source": [
    "In bi directional bigram model, i am simply picking a word at the middle, sending it to the forward bigram first, than backward bigram, both return the next occuring words, and i send those words back to respective models and generate a whole verse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01fdaa65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تو کیا ہے تو فکر سے بھی نہیں ہے\n",
      "ہے تو کیا ہے وہ بھی نہیں ہے کہ\n",
      "\n",
      "دل میں بھی نہیں ہوتے ہیں ہم نے بھی\n",
      "وہ دانائے سبل ختم عہدِ ہجر کی طرح سے\n",
      "\n",
      "ہیں ہم نے زخم جگر کے لیے آ گیا\n",
      "کیا ہے مجھ کو عداوت ہی نہیں ہے کہ\n",
      "\n",
      "ہے تو کیا ہے مجھ کو بھی نہیں ہے\n",
      "ہے تو کیا ہے کچھ نہ ہو کر کے\n",
      "\n",
      "اس کے دیکھتے ہیں جوہر آئینہ ہے کہ میں\n",
      "کیا ہے اس کی صدا ہو کر کے لیے\n",
      "\n",
      "تو کیا ہے مجھ کو بھی نہیں ہے کہ\n",
      "یوں ہی کیوں نہ تھا کہ میں نے بھی\n",
      "\n",
      "ہے تو کیا ہے بجلی سے بھی نہیں ہے\n",
      "کیا ہے اس کا مزا پایا ہے کہ میں\n",
      "\n",
      "tw kya haay tw fkr say bhy nhayn haay\n",
      "haay tw kya haay wha bhy nhayn haay kha\n",
      "\n",
      "dl myn bhy nhayn hawtay hayn ham nay bhy\n",
      "wha danaiay sbl khtm ahadِ hajr ky tarha say\n",
      "\n",
      "hayn ham nay zakhm jghr kay lyay aa ghya\n",
      "kya haay mjh kw adawt hay nhayn haay kha\n",
      "\n",
      "haay tw kya haay mjh kw bhy nhayn haay\n",
      "haay tw kya haay kchh nha haw kr kay\n",
      "\n",
      "as kay dykhtay hayn jwhar aaiynha haay kha myn\n",
      "kya haay as ky sada haw kr kay lyay\n",
      "\n",
      "tw kya haay mjh kw bhy nhayn haay kha\n",
      "ywn hay kywn nha tha kha myn nay bhy\n",
      "\n",
      "haay tw kya haay bjly say bhy nhayn haay\n",
      "kya haay as ka mzaa paya haay kha myn\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poet_line=''\n",
    "new_line=[]\n",
    "Ghazal=[]\n",
    "rand_range=len(unique_words)\n",
    "\n",
    "\n",
    "for j in range(0,14):\n",
    "    idx=random.randint(0,rand_range)\n",
    "    middle_word=bigram[idx][0]\n",
    "    middle_word_fwd=middle_word\n",
    "    middle_word_bck=middle_word\n",
    "    new_line.append(middle_word)\n",
    "    previou_word=''\n",
    "    next_word=''\n",
    "    for i in range(0,8):\n",
    "        if(i%2==0):\n",
    "            try:\n",
    "                next_word=bigram_gen(bigram,middle_word_fwd,bigram_freq,unigram_freq_dict,no_of_unique_words)\n",
    "                middle_word_fwd=next_word\n",
    "                new_line = new_line + [next_word]\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            try:\n",
    "                previou_word=Back_bigram_gen(Back_bigram,middle_word_bck,Back_bigram_freq,unigram_freq_dict,no_of_unique_words)\n",
    "                middle_word_bck=previou_word\n",
    "                new_line =  [previou_word] + new_line \n",
    "            except:\n",
    "                pass\n",
    "    poet_line=' '.join(new_line)\n",
    "    Ghazal.append(poet_line)\n",
    "    print(poet_line)\n",
    "    poet_line=''\n",
    "    new_line=[]\n",
    "    if(j%2==1):\n",
    "        print()\n",
    "\n",
    "Roman_Ghazal=[]\n",
    "for sentence in Ghazal:\n",
    "    Roman_Ghazal.append(urdu_to_roman(sentence))\n",
    "\n",
    "i=0\n",
    "for sentence in Roman_Ghazal:\n",
    "    print(sentence)\n",
    "    if(i%2==1):\n",
    "        print()\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187fc05e",
   "metadata": {},
   "source": [
    "# Generating Poetry using Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3562f865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ھے کہ میں نے بھی نہیں ہے کہ میں\n",
      "اک عمر بھر کے لیے آ گیا ہے کہ\n",
      "\n",
      "ہوا ہے کہ میں نے بھی نہیں ہے کہ\n",
      "آخر شب غم سے بھی نہیں ہے کہ میں\n",
      "\n",
      "پر ہے کہ میں نے بھی نہیں ہے کہ\n",
      "سمجھتے ہیں ہم نے بھی نہیں ہے کہ میں\n",
      "\n",
      "ایک ہی نہیں ہے کہ میں نے بھی نہیں\n",
      "لے کے لیے آ گیا ہے کہ میں نے\n",
      "\n",
      "اتنی سی ہے کہ میں نے بھی نہیں ہے\n",
      "کے لیے آ گیا ہے کہ میں نے بھی\n",
      "\n",
      "از خود کو بھی نہیں ہے کہ میں نے\n",
      "نبرد تھا کہ میں نے بھی نہیں ہے کہ\n",
      "\n",
      "زیبائی کا ہے کہ میں نے بھی نہیں ہے\n",
      "سنگ دل میں نے بھی نہیں ہے کہ میں\n",
      "\n",
      "آئینے میں نے بھی نہیں ہے کہ میں نے\n",
      "کیوں نہ ہو کر کے لیے آ گیا ہے\n",
      "\n",
      "hay kha myn nay bhy nhayn haay kha myn\n",
      "ak amr bhr kay lyay aa ghya haay kha\n",
      "\n",
      "hawa haay kha myn nay bhy nhayn haay kha\n",
      "aakhr shb ghm say bhy nhayn haay kha myn\n",
      "\n",
      "pr haay kha myn nay bhy nhayn haay kha\n",
      "smjhtay hayn ham nay bhy nhayn haay kha myn\n",
      "\n",
      "ayk hay nhayn haay kha myn nay bhy nhayn\n",
      "lay kay lyay aa ghya haay kha myn nay\n",
      "\n",
      "atny sy haay kha myn nay bhy nhayn haay\n",
      "kay lyay aa ghya haay kha myn nay bhy\n",
      "\n",
      "aza khwd kw bhy nhayn haay kha myn nay\n",
      "nbrd tha kha myn nay bhy nhayn haay kha\n",
      "\n",
      "zaybaiy ka haay kha myn nay bhy nhayn haay\n",
      "sngh dl myn nay bhy nhayn haay kha myn\n",
      "\n",
      "aaiynay myn nay bhy nhayn haay kha myn nay\n",
      "kywn nha haw kr kay lyay aa ghya haay\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poet_line=''\n",
    "new_line=[]\n",
    "Ghazal=[]\n",
    "rand_range=len(unique_words)\n",
    "\n",
    "for j in range(0,16):\n",
    "\n",
    "    idx=random.randint(0,rand_range)\n",
    "    start_word=bigram[idx][0]\n",
    "    new_line.append(start_word)\n",
    "    for i in range(0,8):\n",
    "        try:\n",
    "            next_word=bigram_gen(bigram,start_word,bigram_freq,unigram_freq_dict,no_of_unique_words)\n",
    "            new_line.append(next_word)\n",
    "            start_word=next_word\n",
    "        except:\n",
    "            pass\n",
    "    poet_line=' '.join(new_line)\n",
    "    Ghazal.append(poet_line)\n",
    "    print(poet_line)\n",
    "    poet_line=''\n",
    "    new_line=[]\n",
    "    if(j%2==1):\n",
    "        print()\n",
    "\n",
    "Roman_Ghazal=[]\n",
    "for sentence in Ghazal:\n",
    "    Roman_Ghazal.append(urdu_to_roman(sentence))\n",
    "\n",
    "i=0\n",
    "for sentence in Roman_Ghazal:\n",
    "    print(sentence)\n",
    "    if(i%2==1):\n",
    "        print()\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13d6711",
   "metadata": {},
   "source": [
    "# Generating Poetry using Backwards Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ebab42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ہے تو کیا ہے تو کیا ہے ہر رنگ\n",
      "کیا ہے تو کیا ہے کہ تجھ سا لگے\n",
      "\n",
      "ہے تو کیا ہے تو کیا ہے اس کا\n",
      "تو کیا ہے دل میں بھی نہیں ہوتی جاتی\n",
      "\n",
      "کیا ہے اس کے دیکھتے ہیں ہم نے جگ\n",
      "کیا ہے تو کیا ہے تو کیا ہے اس\n",
      "\n",
      "تو کیا ہے تو کیا ہے مجھ سے تری\n",
      "تو کیا ہے تو کیا ہے اس کی رات\n",
      "\n",
      "کیا ہے اس کے دیکھتے ہیں ہم نے زخم\n",
      "کیا ہے تو کیا ہے دل میں بھی نہیں\n",
      "\n",
      "کیا ہے تو کیا ہے تو کیا ہے دل\n",
      "تو کیا ہے کہ یوں ہی کیوں نہ پایا\n",
      "\n",
      "تو کیا ہے تو کیا ہے دل و گل\n",
      "ہے تو کیا ہے تو کیا ہے دل میں\n",
      "\n",
      "تو کیا ہے اس کے دیکھتے ہیں ہم نے\n",
      "ہے تو کیا ہے تو کیا ہے دل میں\n",
      "\n",
      "haay tw kya haay tw kya haay har rngh\n",
      "kya haay tw kya haay kha tjh sa lghay\n",
      "\n",
      "haay tw kya haay tw kya haay as ka\n",
      "tw kya haay dl myn bhy nhayn hawty jaty\n",
      "\n",
      "kya haay as kay dykhtay hayn ham nay jgh\n",
      "kya haay tw kya haay tw kya haay as\n",
      "\n",
      "tw kya haay tw kya haay mjh say try\n",
      "tw kya haay tw kya haay as ky rat\n",
      "\n",
      "kya haay as kay dykhtay hayn ham nay zakhm\n",
      "kya haay tw kya haay dl myn bhy nhayn\n",
      "\n",
      "kya haay tw kya haay tw kya haay dl\n",
      "tw kya haay kha ywn hay kywn nha paya\n",
      "\n",
      "tw kya haay tw kya haay dl w ghl\n",
      "haay tw kya haay tw kya haay dl myn\n",
      "\n",
      "tw kya haay as kay dykhtay hayn ham nay\n",
      "haay tw kya haay tw kya haay dl myn\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Ghazal=[]\n",
    "poet_line=''\n",
    "new_line=[]\n",
    "Ghazal=[]\n",
    "rand_range=len(unique_words)\n",
    "\n",
    "for j in range(0,16):\n",
    "\n",
    "    idx=random.randint(0,rand_range)\n",
    "    start_word=Back_bigram[idx][0]\n",
    "    new_line.append(start_word)\n",
    "    for i in range(0,8):\n",
    "        try:\n",
    "            next_word=Back_bigram_gen(Back_bigram,start_word,Back_bigram_freq,unigram_freq_dict,no_of_unique_words)\n",
    "            new_line.append(next_word)\n",
    "            start_word=next_word\n",
    "        except:\n",
    "            pass\n",
    "    new_line.reverse()\n",
    "    poet_line=' '.join(new_line)\n",
    "    Ghazal.append(poet_line)\n",
    "    print(poet_line)\n",
    "    poet_line=''\n",
    "    new_line=[]\n",
    "    if(j%2==1):\n",
    "        print()\n",
    "\n",
    "Roman_Ghazal=[]\n",
    "for sentence in Ghazal:\n",
    "    Roman_Ghazal.append(urdu_to_roman(sentence))\n",
    "\n",
    "i=0\n",
    "for sentence in Roman_Ghazal:\n",
    "    print(sentence)\n",
    "    if(i%2==1):\n",
    "        print()\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca4822b",
   "metadata": {},
   "source": [
    "# Generating Poetry using Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26a4c16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "جنوں تھے وہ ہے کہ تم ہو نہیں سکتا\n",
      "مری نگاہ میں اس کے دیکھتے ہیں ہم لوگ\n",
      "\n",
      "زنداں میں بھی ہوتے ہیں ہم لوگ کہتے ہیں\n",
      "نیہ کی ہوا جاتا ہے کہ تم کو اس\n",
      "\n",
      "برگ گل بنا کر چلے ہے میاں کب تک\n",
      "سے ملتا ہے کہ تم کو اس گلی میں\n",
      "\n",
      "دین و دل و جاں کی ہے کہ تم\n",
      "بس اک نگاہ تو نے مجھ کو ڈھونڈتے ہیں\n",
      "\n",
      "ہے کہ تم کو اس گلی میں اس کے\n",
      "کیا کرے گا تجھ کو ڈھونڈتے ہیں ہم لوگ\n",
      "\n",
      "گھر سے باہر ہے دم بہ دم بہ دم\n",
      "اگر اجازت ہو نہیں سکتا اگر استوار نہیں ہے\n",
      "\n",
      "واہ ری تیری ضرب تجھ سے کہیں اُس کو\n",
      "اپنا کلی کلی کلی کو ڈھونڈتے ہیں ہم لوگ\n",
      "\n",
      "jnwn thay wha haay kha tm haw nhayn skta\n",
      "mry nghaha myn as kay dykhtay hayn ham lwgh\n",
      "\n",
      "zandan myn bhy hawtay hayn ham lwgh khatay hayn\n",
      "nyha ky hawa jata haay kha tm kw as\n",
      "\n",
      "brgh ghl bna kr chlay haay myan kb tk\n",
      "say mlta haay kha tm kw as ghly myn\n",
      "\n",
      "dyn w dl w jan ky haay kha tm\n",
      "bs ak nghaha tw nay mjh kw dahwndatay hayn\n",
      "\n",
      "haay kha tm kw as ghly myn as kay\n",
      "kya kray gha tjh kw dahwndatay hayn ham lwgh\n",
      "\n",
      "ghhr say bahar haay dm bha dm bha dm\n",
      "aghr ajazat haw nhayn skta aghr astwar nhayn haay\n",
      "\n",
      "waha ry tyry zurb tjh say khayn aُs kw\n",
      "apna kly kly kly kw dahwndatay hayn ham lwgh\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_line=[]\n",
    "poet_line=''\n",
    "rand_range=len(Trigram)\n",
    "Ghazal=[]\n",
    "\n",
    "#print(start_word)\n",
    "\n",
    "for j in range(0,14):\n",
    "    idx=random.randint(0,rand_range)\n",
    "    start_word=Trigram[idx][0]\n",
    "    new_line.append(start_word)\n",
    "    for i in range(0,4):\n",
    "        try:\n",
    "            second_word,third_word=trigram_gen(Trigram,bigram_freq,start_word,trigram_freq,unigram_freq_dict,no_of_unique_words)\n",
    "            new_line.append(second_word)\n",
    "            new_line.append(third_word)\n",
    "            start_word=third_word\n",
    "        except :\n",
    "            pass\n",
    "    poet_line=' '.join(new_line)\n",
    "    Ghazal.append(poet_line)\n",
    "    print(poet_line)\n",
    "    poet_line=''\n",
    "    new_line=[]\n",
    "    if(j%2==1):\n",
    "        print()\n",
    "        \n",
    "\n",
    "Roman_Ghazal=[]\n",
    "for sentence in Ghazal:\n",
    "    Roman_Ghazal.append(urdu_to_roman(sentence))\n",
    "\n",
    "i=0\n",
    "for sentence in Roman_Ghazal:\n",
    "    print(sentence)\n",
    "    if(i%2==1):\n",
    "        print()\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c48b5e4",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c99b76",
   "metadata": {},
   "source": [
    "As you can see i have genrated poetry using, bigram, backward bigram, bi directinal bigram and trigram.\n",
    "There isn't much diffrence in forward bigram and backward bigram as both of produce almost same probabilities for the occurances of words. but when we combine both of them into bidirectinal bigrams a significant impoved version is seen as generated by bi directional bigram. \n",
    "But still the best version of it is generated by trigrams, as the occuring probailities were not spread too thin, and words in words of 3 pairs occur are more meaningful and give more context and meaning compared to the bi directional bigrams"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
